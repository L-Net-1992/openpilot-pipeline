{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "import matplotlib.pyplot as plt\n",
    "from train.dataloader import CommaDataset, BatchDataLoader, BackgroundGenerator\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "from common.transformations.camera import eon_intrinsics, FULL_FRAME_SIZE as eon_f_frame_size, get_view_frame_from_calib_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_height, plot_img_width = 480, 640 # can be reduced for wandb\n",
    "width, height = eon_f_frame_size\n",
    "\n",
    "_BB_SCALE = eon_f_frame_size[0] / plot_img_width\n",
    "calib_scale = eon_f_frame_size[0] / plot_img_width\n",
    "_BB_TO_FULL_FRAME = np.asarray([\n",
    "    [_BB_SCALE, 0., 0.],\n",
    "    [0., _BB_SCALE, 0.],\n",
    "    [0., 0., 1.]])\n",
    "_CALIB_BB_TO_FULL = np.asarray([\n",
    "    [calib_scale, 0., 0.],\n",
    "    [0., calib_scale, 0.],\n",
    "    [0., 0., 1.]])\n",
    "\n",
    "PATH = 4955\n",
    "LANE_LINES = PATH+528\n",
    "LANE_LINE_PROB = LANE_LINES+8\n",
    "ROAD_EDGES = LANE_LINE_PROB+264\n",
    "LEADS = ROAD_EDGES+102\n",
    "LEAD_PROB = LEADS+3\n",
    "DESIRE_STATE = LEAD_PROB+8\n",
    "META = DESIRE_STATE+80\n",
    "POSE = META+12\n",
    "RECURRENT_STATE = POSE+512\n",
    "\n",
    "TRAJECTORY_SIZE = 33\n",
    "MAX_DISTANCE = 140.\n",
    "LANE_OFFSET = 1.8\n",
    "MAX_REL_V = 10.\n",
    "\n",
    "LEAD_X_SCALE = 10\n",
    "LEAD_Y_SCALE = 10\n",
    "PLAN_MEAN = 0\n",
    "PLAN_STD = 1\n",
    "PLAN_X = 0\n",
    "PLAN_Y = 1\n",
    "LANE_MEAN = 0\n",
    "LANE_Y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_points_and_std_values(path):\n",
    "    points_indices = np.arange(0, path.shape[-1], 2)\n",
    "    std_indices = np.arange(1, path.shape[-1], 2)\n",
    "\n",
    "    points = path[:, points_indices]\n",
    "    std_values = path[:, std_indices]\n",
    "\n",
    "    return points, std_values\n",
    "\n",
    "\n",
    "def extract_preds(res):\n",
    "    # N is batch_size\n",
    "\n",
    "    plan_start_idx = 0\n",
    "    plan_end_idx = 4955\n",
    "\n",
    "    lanes_start_idx = plan_end_idx\n",
    "    lanes_end_idx = lanes_start_idx + 528\n",
    "\n",
    "    lane_lines_prob_start_idx = lanes_end_idx\n",
    "    lane_lines_prob_end_idx = lane_lines_prob_start_idx + 8\n",
    "\n",
    "    road_start_idx = lane_lines_prob_end_idx\n",
    "    road_end_idx = road_start_idx + 264\n",
    "\n",
    "    plan = res[:, plan_start_idx:plan_end_idx]  # (N, 4955)\n",
    "    paths = np.array(np.split(plan, 5, axis=1)).reshape(-1, 5, 991)  # (N, 5, 991)\n",
    "    path_probs = paths[:, :, -1]  # (N, 5)\n",
    "    paths = paths[:, :, :-1].reshape(-1, 5, 2, 33, 15)  # (N, 5, 2, 33, 15)\n",
    "\n",
    "    best_idx = np.argmax(path_probs, axis=1)[0]  # (N,)\n",
    "    best_path = paths[:, best_idx, ...]  # (N, 2, 33, 15)\n",
    "\n",
    "    lanes = res[:, lanes_start_idx:lanes_end_idx]\n",
    "    lane_road = res[:, road_start_idx:road_end_idx]\n",
    "\n",
    "    ll_t = lanes[:, 0:66]\n",
    "\n",
    "    ll_t2 = lanes[:, 66:132]\n",
    "    outer_left_lane, outer_left_lane_std = seperate_points_and_std_values(ll_t)\n",
    "    inner_left_lane, inner_left_lane_std = seperate_points_and_std_values(ll_t2)\n",
    "\n",
    "    l_t = lanes[:, 132:198]\n",
    "    l_t2 = lanes[:, 198:264]\n",
    "    outer_right_lane, outer_right_lane_std = seperate_points_and_std_values(l_t2)\n",
    "    inner_right_lane, inner_right_lane_std = seperate_points_and_std_values(l_t)\n",
    "\n",
    "    roadr_t = lane_road[:, 0:66]\n",
    "    roadr_t2 = lane_road[:, 66:132]\n",
    "    left_road_edge, left_road_edge_std = seperate_points_and_std_values(roadr_t)\n",
    "    right_road_edge, right_road_edge_std = seperate_points_and_std_values(roadr_t2)\n",
    "\n",
    "    # lanelines with std\n",
    "    lanelines = [\n",
    "        (left_road_edge, left_road_edge_std, 'yellow'),\n",
    "        # (outer_left_lane,  outer_left_lane_std, 'sandybrown'),\n",
    "        (inner_left_lane,  inner_left_lane_std, 'white'),\n",
    "        (inner_right_lane, inner_right_lane_std, 'white'),\n",
    "        # (outer_right_lane, outer_right_lane_std, 'sandybrown'),\n",
    "        (right_road_edge, right_road_edge_std, 'yellow'),\n",
    "    ]\n",
    "\n",
    "    return lanelines, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calibration:\n",
    "  def __init__(self, rpy, intrinsic=eon_intrinsics):\n",
    "    self.intrinsic = intrinsic\n",
    "    self.extrinsics_matrix = get_view_frame_from_calib_frame(rpy[0], rpy[1], rpy[2], 0)[:,:3]\n",
    "    self.zoom = _CALIB_BB_TO_FULL[0, 0]\n",
    "\n",
    "  def car_space_to_ff(self, x, y, z):\n",
    "    car_space_projective = np.column_stack((x, y, z)).T\n",
    "    ep = self.extrinsics_matrix.dot(car_space_projective)\n",
    "    kep = self.intrinsic.dot(ep)\n",
    "    return (kep[:-1, :] / kep[-1, :]).T\n",
    "\n",
    "  def car_space_to_bb(self, x, y, z):\n",
    "    pts = self.car_space_to_ff(x, y, z)\n",
    "    return pts / self.zoom\n",
    "\n",
    "\n",
    "def project_path(path, calibration, z_off=1.22):\n",
    "  '''Projects paths from calibration space (model input/output) to image space.'''\n",
    "\n",
    "  x = path[:, 0]\n",
    "  y = path[:, 1]\n",
    "  z = path[:, 2] + z_off\n",
    "  pts = calibration.car_space_to_bb(x, y, z)\n",
    "  pts[pts < 0] = np.nan\n",
    "  valid = np.isfinite(pts).all(axis=1)\n",
    "  pts = pts[valid].astype(int)\n",
    "\n",
    "  return pts\n",
    "\n",
    "\n",
    "def draw_path(calib_path, img, calibration, width=1, height=1.2, fill_color=(128,0,255), line_color=(0,255,0)):\n",
    "  calib_path_l = calib_path - np.array([0, width, 0])\n",
    "  calib_path_r = calib_path + np.array([0, width, 0])\n",
    "\n",
    "  img_pts_l = project_path(calib_path_l, calibration, z_off=height)\n",
    "  img_pts_r = project_path(calib_path_r, calibration, z_off=height)\n",
    "\n",
    "  for i in range(1, len(img_pts_l)):\n",
    "    u1,v1,u2,v2 = np.append(img_pts_l[i-1], img_pts_r[i-1])\n",
    "    u3,v3,u4,v4 = np.append(img_pts_l[i], img_pts_r[i])\n",
    "    pts = np.array([[u1,v1],[u2,v2],[u4,v4],[u3,v3]], np.int32).reshape((-1,1,2))\n",
    "    cv2.fillPoly(img,[pts],fill_color)\n",
    "    cv2.polylines(img,[pts],True,line_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 33, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_preds = np.load('/home/nikita/data/2021-09-14--09-19-21/25/xyz_preds.npz')\n",
    "real_paths_xyz = np.stack((real_preds['x'], real_preds['y'], real_preds['z']), axis=-1)\n",
    "real_paths_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached paths to videos and GTs...\n",
      "Total # segments 72\n",
      "Subset # segments: 58\n",
      "t_idx: 0\n",
      "t_idx: 100\n",
      "t_idx: 200\n",
      "t_idx: 300\n",
      "t_idx: 400\n",
      "t_idx: 500\n",
      "t_idx: 600\n",
      "t_idx: 700\n",
      "t_idx: 800\n",
      "t_idx: 900\n",
      "t_idx: 1000\n"
     ]
    }
   ],
   "source": [
    "comma_recordings_basedir = '/home/nikita/data'\n",
    "path_to_onnx_model = 'train/supercombo.onnx'\n",
    "os.makedirs('outs', exist_ok=True)\n",
    "\n",
    "train_split = 0.8\n",
    "seq_len = 1001\n",
    "single_frame_batches = False\n",
    "prefetch_factor = 1\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "\n",
    "train_dataset = CommaDataset(comma_recordings_basedir, train_split=train_split, seq_len=seq_len,\n",
    "                                shuffle=True, single_frame_batches=single_frame_batches, seed=42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=None, num_workers=num_workers, shuffle=False,\n",
    "                        prefetch_factor=prefetch_factor, persistent_workers=True, collate_fn=None)\n",
    "train_loader = BatchDataLoader(train_loader, batch_size=batch_size)\n",
    "train_loader = BackgroundGenerator(train_loader)\n",
    "\n",
    "model = onnx.load(path_to_onnx_model)\n",
    "\n",
    "input_names = [node.name for node in model.graph.input]\n",
    "output_names = [node.name for node in model.graph.output]\n",
    "\n",
    "providers = ['CPUExecutionProvider']\n",
    "onnxruntime_model = rt.InferenceSession(path_to_onnx_model, providers=providers)\n",
    "\n",
    "recurrent_state = np.zeros((1, 512), dtype=np.float32)\n",
    "\n",
    "for batch in train_loader:\n",
    "    stacked_frames, plans, plans_probs, segment_finished, sequence_finished, bgr_frames = batch\n",
    "\n",
    "    for t_idx in range(seq_len):\n",
    "\n",
    "        input_frame = stacked_frames[0:1, t_idx, ...].numpy().astype(np.float32)\n",
    "        bgr_frame = bgr_frames[0, t_idx, ...].numpy()\n",
    "\n",
    "        inputs = {\n",
    "            'input_imgs': input_frame,\n",
    "            'desire': np.zeros((1, 8), dtype=np.float32),\n",
    "            'traffic_convention': np.array([0, 1], dtype=np.float32).reshape(1, 2),\n",
    "            'initial_state': recurrent_state,\n",
    "        }\n",
    "\n",
    "        outs = onnxruntime_model.run(output_names, inputs)[0]\n",
    "        lanelines, best_path = extract_preds(outs)\n",
    "        recurrent_state = outs[:, -512:]\n",
    "\n",
    "        if t_idx % 100 == 0:\n",
    "            print('t_idx:', t_idx)\n",
    "            # plot predictions\n",
    "            rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "            img_gt = np.zeros((plot_img_height, plot_img_width, 3), dtype='uint8')\n",
    "            zoom_matrix = _BB_TO_FULL_FRAME\n",
    "            cv2.warpAffine(rgb_frame, zoom_matrix[:2], (img_gt.shape[1], img_gt.shape[0]), dst=img_gt, flags=cv2.WARP_INVERSE_MAP)\n",
    "            img_pred = img_gt.copy()\n",
    "\n",
    "            rpy_calib_gt = [0.00018335809, 0.034165092, -0.014245722]  # real calibration values during this ride\n",
    "            rpy_calib_pred = [0, 0, 0]  # calibration we currently use for pre-processing\n",
    "\n",
    "            calibration_gt = Calibration(rpy_calib_gt)\n",
    "            calibration_pred = Calibration(rpy_calib_pred)\n",
    "\n",
    "            path_xyz_gt = real_paths_xyz[t_idx]\n",
    "            path_xyz_pred = best_path[0, 0, :, :3]\n",
    "\n",
    "            draw_path(path_xyz_gt, img_gt, calibration_gt)\n",
    "            draw_path(path_xyz_pred, img_pred, calibration_pred)\n",
    "\n",
    "            plot_width = 15\n",
    "            plot_height = plot_width * (height / width)\n",
    "            plt.figure(figsize=(plot_width, plot_height))\n",
    "\n",
    "            plt.imsave(f'outs/{t_idx}-gt.png', img_gt)\n",
    "            plt.imsave(f'outs/{t_idx}-pred.png', img_pred)\n",
    "            plt.close()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "502b2082a03da827e4d45daf792504142f6621507873a9075db59c3487ea81e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('comma': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
