{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx2pytorch import ConvertModel\n",
    "import onnx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_onnx_model = '/Users/macbook/Desktop/supercombo.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(path_to_onnx_model)\n",
    "pytorch_model = ConvertModel(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertModel(\n",
       "  (Conv_634): Conv2d(12, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (BatchNormalization_636): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(32, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_637): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_638): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (BatchNormalization_640): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(32, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_641): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_642): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_644): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(16, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_645): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "  (BatchNormalization_647): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(16, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_648): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_649): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_651): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(16, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_652): Add()\n",
       "  (Conv_653): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_655): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(96, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_656): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_657): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "  (BatchNormalization_659): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(96, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_660): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_661): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_663): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(24, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_664): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_666): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(144, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_667): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_668): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "  (BatchNormalization_670): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(144, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_671): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_672): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_674): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(24, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_675): Add()\n",
       "  (Conv_676): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_678): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(144, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_679): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_680): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "  (BatchNormalization_682): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(144, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_683): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_684): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_686): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(24, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_687): Add()\n",
       "  (Conv_688): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_690): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(144, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_691): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_692): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "  (BatchNormalization_694): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(144, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_695): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_696): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_698): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(48, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_699): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_701): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(288, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_702): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_703): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "  (BatchNormalization_705): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(288, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_706): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_707): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_709): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(48, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_710): Add()\n",
       "  (Conv_711): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_713): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(288, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_714): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_715): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "  (BatchNormalization_717): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(288, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_718): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_719): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_721): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(48, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_722): Add()\n",
       "  (Conv_723): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_725): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(288, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_726): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_727): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "  (BatchNormalization_729): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(288, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_730): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_731): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_733): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(88, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_734): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_736): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_737): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_738): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "  (BatchNormalization_740): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_741): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_742): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_744): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(88, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_745): Add()\n",
       "  (Conv_746): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_748): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_749): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_750): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "  (BatchNormalization_752): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_753): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_754): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_756): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(88, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_757): Add()\n",
       "  (Conv_758): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_760): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_761): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_762): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "  (BatchNormalization_764): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_765): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_766): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_768): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(88, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_769): Add()\n",
       "  (Conv_770): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_772): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_773): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_774): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "  (BatchNormalization_776): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(528, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_777): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_778): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_780): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(120, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_781): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_783): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_784): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_785): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "  (BatchNormalization_787): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_788): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_789): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_791): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(120, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_792): Add()\n",
       "  (Conv_793): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_795): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_796): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_797): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "  (BatchNormalization_799): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_800): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_801): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_803): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(120, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_804): Add()\n",
       "  (Conv_805): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_807): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_808): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_809): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "  (BatchNormalization_811): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_812): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_813): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_815): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(120, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_816): Add()\n",
       "  (Conv_817): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_819): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_820): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_821): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
       "  (BatchNormalization_823): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(720, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_824): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_825): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_827): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(208, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_828): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_830): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_831): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_832): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "  (BatchNormalization_834): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_835): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_836): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_838): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(208, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_839): Add()\n",
       "  (Conv_840): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_842): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_843): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_844): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "  (BatchNormalization_846): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_847): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_848): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_850): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(208, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_851): Add()\n",
       "  (Conv_852): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_854): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_855): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_856): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "  (BatchNormalization_858): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_859): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_860): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_862): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(208, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_863): Add()\n",
       "  (Conv_864): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_866): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_867): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_868): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "  (BatchNormalization_870): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_871): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_872): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_874): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(208, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_875): Add()\n",
       "  (Conv_876): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_878): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_879): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_880): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "  (BatchNormalization_882): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(1248, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_883): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_884): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_886): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(352, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv_887): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_889): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(2112, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_890): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_891): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "  (BatchNormalization_893): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(2112, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_894): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_895): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_897): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(352, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Add_898): Add()\n",
       "  (Conv_899): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), groups=352, bias=False)\n",
       "  (BatchNormalization_901): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(352, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Elu_902): ELU(alpha=1.0, inplace=True)\n",
       "  (Conv_903): Conv2d(352, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (BatchNormalization_905): BatchNormWrapper(\n",
       "    (bnu): BatchNormUnsafe(32, eps=0.0010000000474974513, momentum=0.9900000095367432, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Flatten_906): Flatten()\n",
       "  (Elu_907): ELU(alpha=1.0, inplace=True)\n",
       "  (Gemm_908): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (Relu_909): ReLU(inplace=True)\n",
       "  (Gemm_910): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (Relu_911): ReLU(inplace=True)\n",
       "  (Gemm_912): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_913): ReLU(inplace=True)\n",
       "  (Gemm_914): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_915): ReLU(inplace=True)\n",
       "  (Gemm_916): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (Relu_917): ReLU(inplace=True)\n",
       "  (Gemm_918): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (Add_919): Add()\n",
       "  (Relu_920): ReLU(inplace=True)\n",
       "  (Gemm_921): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_922): ReLU(inplace=True)\n",
       "  (Gemm_923): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_924): Add()\n",
       "  (Relu_925): ReLU(inplace=True)\n",
       "  (Gemm_926): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_927): ReLU(inplace=True)\n",
       "  (Gemm_928): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_929): Add()\n",
       "  (Relu_930): ReLU(inplace=True)\n",
       "  (Gemm_931): Linear(in_features=64, out_features=48, bias=True)\n",
       "  (Gemm_932): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Gemm_933): Linear(in_features=32, out_features=12, bias=True)\n",
       "  (Elu_935): ELU(alpha=1.0, inplace=True)\n",
       "  (Gemm_936): Linear(in_features=1034, out_features=1024, bias=True)\n",
       "  (Relu_937): ReLU(inplace=True)\n",
       "  (Gemm_938): Linear(in_features=1024, out_features=1536, bias=True)\n",
       "  (Gemm_939): Linear(in_features=512, out_features=1536, bias=True)\n",
       "  (Split_940): Split()\n",
       "  (Split_943): Split()\n",
       "  (Add_946): Add()\n",
       "  (Sigmoid_947): Sigmoid()\n",
       "  (Add_948): Add()\n",
       "  (Sigmoid_949): Sigmoid()\n",
       "  (Mul_950): mul()\n",
       "  (Add_951): Add()\n",
       "  (Tanh_952): mul()\n",
       "  (Sub_953): mul()\n",
       "  (Mul_954): mul()\n",
       "  (Add_955): Add()\n",
       "  (Gemm_957): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "  (Relu_958): ReLU(inplace=True)\n",
       "  (Gemm_959): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (Relu_960): ReLU(inplace=True)\n",
       "  (Gemm_961): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (Relu_962): ReLU(inplace=True)\n",
       "  (Gemm_963): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (Relu_964): ReLU(inplace=True)\n",
       "  (Gemm_965): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (Relu_966): ReLU(inplace=True)\n",
       "  (Gemm_967): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (Relu_968): ReLU(inplace=True)\n",
       "  (Gemm_969): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_970): ReLU(inplace=True)\n",
       "  (Gemm_971): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_972): ReLU(inplace=True)\n",
       "  (Gemm_973): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_974): ReLU(inplace=True)\n",
       "  (Gemm_975): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_976): ReLU(inplace=True)\n",
       "  (Gemm_977): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (Relu_978): ReLU(inplace=True)\n",
       "  (Gemm_979): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (Relu_980): ReLU(inplace=True)\n",
       "  (Gemm_981): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (Relu_982): ReLU(inplace=True)\n",
       "  (Gemm_983): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (Add_984): Add()\n",
       "  (Relu_985): ReLU(inplace=True)\n",
       "  (Gemm_986): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (Relu_987): ReLU(inplace=True)\n",
       "  (Gemm_988): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (Add_989): Add()\n",
       "  (Relu_990): ReLU(inplace=True)\n",
       "  (Gemm_991): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Relu_992): ReLU(inplace=True)\n",
       "  (Gemm_993): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Add_994): Add()\n",
       "  (Relu_995): ReLU(inplace=True)\n",
       "  (Gemm_996): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Relu_997): ReLU(inplace=True)\n",
       "  (Gemm_998): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Add_999): Add()\n",
       "  (Relu_1000): ReLU(inplace=True)\n",
       "  (Gemm_1001): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Relu_1002): ReLU(inplace=True)\n",
       "  (Gemm_1003): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Add_1004): Add()\n",
       "  (Relu_1005): ReLU(inplace=True)\n",
       "  (Gemm_1006): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_1007): ReLU(inplace=True)\n",
       "  (Gemm_1008): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_1009): Add()\n",
       "  (Relu_1010): ReLU(inplace=True)\n",
       "  (Gemm_1011): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_1012): ReLU(inplace=True)\n",
       "  (Gemm_1013): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_1014): Add()\n",
       "  (Relu_1015): ReLU(inplace=True)\n",
       "  (Gemm_1016): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_1017): ReLU(inplace=True)\n",
       "  (Gemm_1018): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_1019): Add()\n",
       "  (Relu_1020): ReLU(inplace=True)\n",
       "  (Gemm_1021): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_1022): ReLU(inplace=True)\n",
       "  (Gemm_1023): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_1024): Add()\n",
       "  (Relu_1025): ReLU(inplace=True)\n",
       "  (Gemm_1026): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Relu_1027): ReLU(inplace=True)\n",
       "  (Gemm_1028): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (Add_1029): Add()\n",
       "  (Relu_1030): ReLU(inplace=True)\n",
       "  (Gemm_1031): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Relu_1032): ReLU(inplace=True)\n",
       "  (Gemm_1033): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (Add_1034): Add()\n",
       "  (Relu_1035): ReLU(inplace=True)\n",
       "  (Gemm_1036): Linear(in_features=256, out_features=4955, bias=True)\n",
       "  (Gemm_1037): Linear(in_features=64, out_features=102, bias=True)\n",
       "  (Gemm_1038): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (Gemm_1039): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (Gemm_1040): Linear(in_features=16, out_features=132, bias=True)\n",
       "  (Gemm_1041): Linear(in_features=32, out_features=132, bias=True)\n",
       "  (Gemm_1042): Linear(in_features=32, out_features=132, bias=True)\n",
       "  (Gemm_1043): Linear(in_features=32, out_features=132, bias=True)\n",
       "  (Gemm_1044): Linear(in_features=32, out_features=132, bias=True)\n",
       "  (Gemm_1045): Linear(in_features=16, out_features=132, bias=True)\n",
       "  (Gemm_1046): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (Constant_1047): Constant(constant=tensor([ 1,  2, 66]))\n",
       "  (Reshape_1048): Reshape(shape=None)\n",
       "  (Constant_1049): Constant(constant=tensor([ 1,  2, 66]))\n",
       "  (Reshape_1050): Reshape(shape=None)\n",
       "  (Constant_1051): Constant(constant=tensor([ 1,  2, 66]))\n",
       "  (Reshape_1052): Reshape(shape=None)\n",
       "  (Constant_1053): Constant(constant=tensor([ 1,  2, 66]))\n",
       "  (Reshape_1054): Reshape(shape=None)\n",
       "  (Flatten_1056): Flatten()\n",
       "  (Constant_1057): Constant(constant=tensor([ 1,  2, 66]))\n",
       "  (Reshape_1058): Reshape(shape=None)\n",
       "  (Constant_1059): Constant(constant=tensor([ 1,  2, 66]))\n",
       "  (Reshape_1060): Reshape(shape=None)\n",
       "  (Flatten_1062): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'input_imgs': torch.zeros((1, 12, 128, 256), dtype=torch.float32), \n",
    "    'desire': torch.zeros((1, 8), dtype=torch.float32), \n",
    "    'traffic_convention': torch.zeros((1,2), dtype=torch.float32), \n",
    "    'initial_state': torch.zeros((1,512), dtype=torch.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6472])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = pytorch_model(**inputs)\n",
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model.zero_grad()\n",
    "outs.backward(torch.randn(outs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "before: Parameter containing:\n",
      "tensor([ 0.2084, -0.1751, -0.0720, -0.0886, -0.1428, -0.3590, -0.0951, -0.2933],\n",
      "       requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('\\nbefore:', pytorch_model.Gemm_1046.bias)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pytorch_model.Gemm_1046.bias = torch.nn.Parameter(torch.zeros_like(pytorch_model.Gemm_1046.bias, dtype=torch.float32))\n",
    "    \n",
    "print('\\nafter:', pytorch_model.Gemm_1046.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in pytorch_model.named_parameters():\n",
    "    if 'Conv_' in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_634.weight requires grad: False\n",
      "BatchNormalization_636.bnu.weight requires grad: True\n",
      "BatchNormalization_636.bnu.bias requires grad: True\n",
      "Conv_638.weight requires grad: False\n",
      "BatchNormalization_640.bnu.weight requires grad: True\n",
      "BatchNormalization_640.bnu.bias requires grad: True\n",
      "Conv_642.weight requires grad: False\n",
      "BatchNormalization_644.bnu.weight requires grad: True\n",
      "BatchNormalization_644.bnu.bias requires grad: True\n",
      "Conv_645.weight requires grad: False\n",
      "BatchNormalization_647.bnu.weight requires grad: True\n",
      "BatchNormalization_647.bnu.bias requires grad: True\n",
      "Conv_649.weight requires grad: False\n",
      "BatchNormalization_651.bnu.weight requires grad: True\n",
      "BatchNormalization_651.bnu.bias requires grad: True\n",
      "Conv_653.weight requires grad: False\n",
      "BatchNormalization_655.bnu.weight requires grad: True\n",
      "BatchNormalization_655.bnu.bias requires grad: True\n",
      "Conv_657.weight requires grad: False\n",
      "BatchNormalization_659.bnu.weight requires grad: True\n",
      "BatchNormalization_659.bnu.bias requires grad: True\n",
      "Conv_661.weight requires grad: False\n",
      "BatchNormalization_663.bnu.weight requires grad: True\n",
      "BatchNormalization_663.bnu.bias requires grad: True\n",
      "Conv_664.weight requires grad: False\n",
      "BatchNormalization_666.bnu.weight requires grad: True\n",
      "BatchNormalization_666.bnu.bias requires grad: True\n",
      "Conv_668.weight requires grad: False\n",
      "BatchNormalization_670.bnu.weight requires grad: True\n",
      "BatchNormalization_670.bnu.bias requires grad: True\n",
      "Conv_672.weight requires grad: False\n",
      "BatchNormalization_674.bnu.weight requires grad: True\n",
      "BatchNormalization_674.bnu.bias requires grad: True\n",
      "Conv_676.weight requires grad: False\n",
      "BatchNormalization_678.bnu.weight requires grad: True\n",
      "BatchNormalization_678.bnu.bias requires grad: True\n",
      "Conv_680.weight requires grad: False\n",
      "BatchNormalization_682.bnu.weight requires grad: True\n",
      "BatchNormalization_682.bnu.bias requires grad: True\n",
      "Conv_684.weight requires grad: False\n",
      "BatchNormalization_686.bnu.weight requires grad: True\n",
      "BatchNormalization_686.bnu.bias requires grad: True\n",
      "Conv_688.weight requires grad: False\n",
      "BatchNormalization_690.bnu.weight requires grad: True\n",
      "BatchNormalization_690.bnu.bias requires grad: True\n",
      "Conv_692.weight requires grad: False\n",
      "BatchNormalization_694.bnu.weight requires grad: True\n",
      "BatchNormalization_694.bnu.bias requires grad: True\n",
      "Conv_696.weight requires grad: False\n",
      "BatchNormalization_698.bnu.weight requires grad: True\n",
      "BatchNormalization_698.bnu.bias requires grad: True\n",
      "Conv_699.weight requires grad: False\n",
      "BatchNormalization_701.bnu.weight requires grad: True\n",
      "BatchNormalization_701.bnu.bias requires grad: True\n",
      "Conv_703.weight requires grad: False\n",
      "BatchNormalization_705.bnu.weight requires grad: True\n",
      "BatchNormalization_705.bnu.bias requires grad: True\n",
      "Conv_707.weight requires grad: False\n",
      "BatchNormalization_709.bnu.weight requires grad: True\n",
      "BatchNormalization_709.bnu.bias requires grad: True\n",
      "Conv_711.weight requires grad: False\n",
      "BatchNormalization_713.bnu.weight requires grad: True\n",
      "BatchNormalization_713.bnu.bias requires grad: True\n",
      "Conv_715.weight requires grad: False\n",
      "BatchNormalization_717.bnu.weight requires grad: True\n",
      "BatchNormalization_717.bnu.bias requires grad: True\n",
      "Conv_719.weight requires grad: False\n",
      "BatchNormalization_721.bnu.weight requires grad: True\n",
      "BatchNormalization_721.bnu.bias requires grad: True\n",
      "Conv_723.weight requires grad: False\n",
      "BatchNormalization_725.bnu.weight requires grad: True\n",
      "BatchNormalization_725.bnu.bias requires grad: True\n",
      "Conv_727.weight requires grad: False\n",
      "BatchNormalization_729.bnu.weight requires grad: True\n",
      "BatchNormalization_729.bnu.bias requires grad: True\n",
      "Conv_731.weight requires grad: False\n",
      "BatchNormalization_733.bnu.weight requires grad: True\n",
      "BatchNormalization_733.bnu.bias requires grad: True\n",
      "Conv_734.weight requires grad: False\n",
      "BatchNormalization_736.bnu.weight requires grad: True\n",
      "BatchNormalization_736.bnu.bias requires grad: True\n",
      "Conv_738.weight requires grad: False\n",
      "BatchNormalization_740.bnu.weight requires grad: True\n",
      "BatchNormalization_740.bnu.bias requires grad: True\n",
      "Conv_742.weight requires grad: False\n",
      "BatchNormalization_744.bnu.weight requires grad: True\n",
      "BatchNormalization_744.bnu.bias requires grad: True\n",
      "Conv_746.weight requires grad: False\n",
      "BatchNormalization_748.bnu.weight requires grad: True\n",
      "BatchNormalization_748.bnu.bias requires grad: True\n",
      "Conv_750.weight requires grad: False\n",
      "BatchNormalization_752.bnu.weight requires grad: True\n",
      "BatchNormalization_752.bnu.bias requires grad: True\n",
      "Conv_754.weight requires grad: False\n",
      "BatchNormalization_756.bnu.weight requires grad: True\n",
      "BatchNormalization_756.bnu.bias requires grad: True\n",
      "Conv_758.weight requires grad: False\n",
      "BatchNormalization_760.bnu.weight requires grad: True\n",
      "BatchNormalization_760.bnu.bias requires grad: True\n",
      "Conv_762.weight requires grad: False\n",
      "BatchNormalization_764.bnu.weight requires grad: True\n",
      "BatchNormalization_764.bnu.bias requires grad: True\n",
      "Conv_766.weight requires grad: False\n",
      "BatchNormalization_768.bnu.weight requires grad: True\n",
      "BatchNormalization_768.bnu.bias requires grad: True\n",
      "Conv_770.weight requires grad: False\n",
      "BatchNormalization_772.bnu.weight requires grad: True\n",
      "BatchNormalization_772.bnu.bias requires grad: True\n",
      "Conv_774.weight requires grad: False\n",
      "BatchNormalization_776.bnu.weight requires grad: True\n",
      "BatchNormalization_776.bnu.bias requires grad: True\n",
      "Conv_778.weight requires grad: False\n",
      "BatchNormalization_780.bnu.weight requires grad: True\n",
      "BatchNormalization_780.bnu.bias requires grad: True\n",
      "Conv_781.weight requires grad: False\n",
      "BatchNormalization_783.bnu.weight requires grad: True\n",
      "BatchNormalization_783.bnu.bias requires grad: True\n",
      "Conv_785.weight requires grad: False\n",
      "BatchNormalization_787.bnu.weight requires grad: True\n",
      "BatchNormalization_787.bnu.bias requires grad: True\n",
      "Conv_789.weight requires grad: False\n",
      "BatchNormalization_791.bnu.weight requires grad: True\n",
      "BatchNormalization_791.bnu.bias requires grad: True\n",
      "Conv_793.weight requires grad: False\n",
      "BatchNormalization_795.bnu.weight requires grad: True\n",
      "BatchNormalization_795.bnu.bias requires grad: True\n",
      "Conv_797.weight requires grad: False\n",
      "BatchNormalization_799.bnu.weight requires grad: True\n",
      "BatchNormalization_799.bnu.bias requires grad: True\n",
      "Conv_801.weight requires grad: False\n",
      "BatchNormalization_803.bnu.weight requires grad: True\n",
      "BatchNormalization_803.bnu.bias requires grad: True\n",
      "Conv_805.weight requires grad: False\n",
      "BatchNormalization_807.bnu.weight requires grad: True\n",
      "BatchNormalization_807.bnu.bias requires grad: True\n",
      "Conv_809.weight requires grad: False\n",
      "BatchNormalization_811.bnu.weight requires grad: True\n",
      "BatchNormalization_811.bnu.bias requires grad: True\n",
      "Conv_813.weight requires grad: False\n",
      "BatchNormalization_815.bnu.weight requires grad: True\n",
      "BatchNormalization_815.bnu.bias requires grad: True\n",
      "Conv_817.weight requires grad: False\n",
      "BatchNormalization_819.bnu.weight requires grad: True\n",
      "BatchNormalization_819.bnu.bias requires grad: True\n",
      "Conv_821.weight requires grad: False\n",
      "BatchNormalization_823.bnu.weight requires grad: True\n",
      "BatchNormalization_823.bnu.bias requires grad: True\n",
      "Conv_825.weight requires grad: False\n",
      "BatchNormalization_827.bnu.weight requires grad: True\n",
      "BatchNormalization_827.bnu.bias requires grad: True\n",
      "Conv_828.weight requires grad: False\n",
      "BatchNormalization_830.bnu.weight requires grad: True\n",
      "BatchNormalization_830.bnu.bias requires grad: True\n",
      "Conv_832.weight requires grad: False\n",
      "BatchNormalization_834.bnu.weight requires grad: True\n",
      "BatchNormalization_834.bnu.bias requires grad: True\n",
      "Conv_836.weight requires grad: False\n",
      "BatchNormalization_838.bnu.weight requires grad: True\n",
      "BatchNormalization_838.bnu.bias requires grad: True\n",
      "Conv_840.weight requires grad: False\n",
      "BatchNormalization_842.bnu.weight requires grad: True\n",
      "BatchNormalization_842.bnu.bias requires grad: True\n",
      "Conv_844.weight requires grad: False\n",
      "BatchNormalization_846.bnu.weight requires grad: True\n",
      "BatchNormalization_846.bnu.bias requires grad: True\n",
      "Conv_848.weight requires grad: False\n",
      "BatchNormalization_850.bnu.weight requires grad: True\n",
      "BatchNormalization_850.bnu.bias requires grad: True\n",
      "Conv_852.weight requires grad: False\n",
      "BatchNormalization_854.bnu.weight requires grad: True\n",
      "BatchNormalization_854.bnu.bias requires grad: True\n",
      "Conv_856.weight requires grad: False\n",
      "BatchNormalization_858.bnu.weight requires grad: True\n",
      "BatchNormalization_858.bnu.bias requires grad: True\n",
      "Conv_860.weight requires grad: False\n",
      "BatchNormalization_862.bnu.weight requires grad: True\n",
      "BatchNormalization_862.bnu.bias requires grad: True\n",
      "Conv_864.weight requires grad: False\n",
      "BatchNormalization_866.bnu.weight requires grad: True\n",
      "BatchNormalization_866.bnu.bias requires grad: True\n",
      "Conv_868.weight requires grad: False\n",
      "BatchNormalization_870.bnu.weight requires grad: True\n",
      "BatchNormalization_870.bnu.bias requires grad: True\n",
      "Conv_872.weight requires grad: False\n",
      "BatchNormalization_874.bnu.weight requires grad: True\n",
      "BatchNormalization_874.bnu.bias requires grad: True\n",
      "Conv_876.weight requires grad: False\n",
      "BatchNormalization_878.bnu.weight requires grad: True\n",
      "BatchNormalization_878.bnu.bias requires grad: True\n",
      "Conv_880.weight requires grad: False\n",
      "BatchNormalization_882.bnu.weight requires grad: True\n",
      "BatchNormalization_882.bnu.bias requires grad: True\n",
      "Conv_884.weight requires grad: False\n",
      "BatchNormalization_886.bnu.weight requires grad: True\n",
      "BatchNormalization_886.bnu.bias requires grad: True\n",
      "Conv_887.weight requires grad: False\n",
      "BatchNormalization_889.bnu.weight requires grad: True\n",
      "BatchNormalization_889.bnu.bias requires grad: True\n",
      "Conv_891.weight requires grad: False\n",
      "BatchNormalization_893.bnu.weight requires grad: True\n",
      "BatchNormalization_893.bnu.bias requires grad: True\n",
      "Conv_895.weight requires grad: False\n",
      "BatchNormalization_897.bnu.weight requires grad: True\n",
      "BatchNormalization_897.bnu.bias requires grad: True\n",
      "Conv_899.weight requires grad: False\n",
      "BatchNormalization_901.bnu.weight requires grad: True\n",
      "BatchNormalization_901.bnu.bias requires grad: True\n",
      "Conv_903.weight requires grad: False\n",
      "BatchNormalization_905.bnu.weight requires grad: True\n",
      "BatchNormalization_905.bnu.bias requires grad: True\n",
      "Gemm_908.weight requires grad: True\n",
      "Gemm_908.bias requires grad: True\n",
      "Gemm_910.weight requires grad: True\n",
      "Gemm_910.bias requires grad: True\n",
      "Gemm_912.weight requires grad: True\n",
      "Gemm_912.bias requires grad: True\n",
      "Gemm_914.weight requires grad: True\n",
      "Gemm_914.bias requires grad: True\n",
      "Gemm_916.weight requires grad: True\n",
      "Gemm_916.bias requires grad: True\n",
      "Gemm_918.weight requires grad: True\n",
      "Gemm_918.bias requires grad: True\n",
      "Gemm_921.weight requires grad: True\n",
      "Gemm_921.bias requires grad: True\n",
      "Gemm_923.weight requires grad: True\n",
      "Gemm_923.bias requires grad: True\n",
      "Gemm_926.weight requires grad: True\n",
      "Gemm_926.bias requires grad: True\n",
      "Gemm_928.weight requires grad: True\n",
      "Gemm_928.bias requires grad: True\n",
      "Gemm_931.weight requires grad: True\n",
      "Gemm_931.bias requires grad: True\n",
      "Gemm_932.weight requires grad: True\n",
      "Gemm_932.bias requires grad: True\n",
      "Gemm_933.weight requires grad: True\n",
      "Gemm_933.bias requires grad: True\n",
      "Gemm_936.weight requires grad: True\n",
      "Gemm_936.bias requires grad: True\n",
      "Gemm_938.weight requires grad: True\n",
      "Gemm_938.bias requires grad: True\n",
      "Gemm_939.weight requires grad: True\n",
      "Gemm_939.bias requires grad: True\n",
      "Gemm_957.weight requires grad: True\n",
      "Gemm_957.bias requires grad: True\n",
      "Gemm_959.weight requires grad: True\n",
      "Gemm_959.bias requires grad: True\n",
      "Gemm_961.weight requires grad: True\n",
      "Gemm_961.bias requires grad: True\n",
      "Gemm_963.weight requires grad: True\n",
      "Gemm_963.bias requires grad: True\n",
      "Gemm_965.weight requires grad: True\n",
      "Gemm_965.bias requires grad: True\n",
      "Gemm_967.weight requires grad: True\n",
      "Gemm_967.bias requires grad: True\n",
      "Gemm_969.weight requires grad: True\n",
      "Gemm_969.bias requires grad: True\n",
      "Gemm_971.weight requires grad: True\n",
      "Gemm_971.bias requires grad: True\n",
      "Gemm_973.weight requires grad: True\n",
      "Gemm_973.bias requires grad: True\n",
      "Gemm_975.weight requires grad: True\n",
      "Gemm_975.bias requires grad: True\n",
      "Gemm_977.weight requires grad: True\n",
      "Gemm_977.bias requires grad: True\n",
      "Gemm_979.weight requires grad: True\n",
      "Gemm_979.bias requires grad: True\n",
      "Gemm_981.weight requires grad: True\n",
      "Gemm_981.bias requires grad: True\n",
      "Gemm_983.weight requires grad: True\n",
      "Gemm_983.bias requires grad: True\n",
      "Gemm_986.weight requires grad: True\n",
      "Gemm_986.bias requires grad: True\n",
      "Gemm_988.weight requires grad: True\n",
      "Gemm_988.bias requires grad: True\n",
      "Gemm_991.weight requires grad: True\n",
      "Gemm_991.bias requires grad: True\n",
      "Gemm_993.weight requires grad: True\n",
      "Gemm_993.bias requires grad: True\n",
      "Gemm_996.weight requires grad: True\n",
      "Gemm_996.bias requires grad: True\n",
      "Gemm_998.weight requires grad: True\n",
      "Gemm_998.bias requires grad: True\n",
      "Gemm_1001.weight requires grad: True\n",
      "Gemm_1001.bias requires grad: True\n",
      "Gemm_1003.weight requires grad: True\n",
      "Gemm_1003.bias requires grad: True\n",
      "Gemm_1006.weight requires grad: True\n",
      "Gemm_1006.bias requires grad: True\n",
      "Gemm_1008.weight requires grad: True\n",
      "Gemm_1008.bias requires grad: True\n",
      "Gemm_1011.weight requires grad: True\n",
      "Gemm_1011.bias requires grad: True\n",
      "Gemm_1013.weight requires grad: True\n",
      "Gemm_1013.bias requires grad: True\n",
      "Gemm_1016.weight requires grad: True\n",
      "Gemm_1016.bias requires grad: True\n",
      "Gemm_1018.weight requires grad: True\n",
      "Gemm_1018.bias requires grad: True\n",
      "Gemm_1021.weight requires grad: True\n",
      "Gemm_1021.bias requires grad: True\n",
      "Gemm_1023.weight requires grad: True\n",
      "Gemm_1023.bias requires grad: True\n",
      "Gemm_1026.weight requires grad: True\n",
      "Gemm_1026.bias requires grad: True\n",
      "Gemm_1028.weight requires grad: True\n",
      "Gemm_1028.bias requires grad: True\n",
      "Gemm_1031.weight requires grad: True\n",
      "Gemm_1031.bias requires grad: True\n",
      "Gemm_1033.weight requires grad: True\n",
      "Gemm_1033.bias requires grad: True\n",
      "Gemm_1036.weight requires grad: True\n",
      "Gemm_1036.bias requires grad: True\n",
      "Gemm_1037.weight requires grad: True\n",
      "Gemm_1037.bias requires grad: True\n",
      "Gemm_1038.weight requires grad: True\n",
      "Gemm_1038.bias requires grad: True\n",
      "Gemm_1039.weight requires grad: True\n",
      "Gemm_1039.bias requires grad: True\n",
      "Gemm_1040.weight requires grad: True\n",
      "Gemm_1040.bias requires grad: True\n",
      "Gemm_1041.weight requires grad: True\n",
      "Gemm_1041.bias requires grad: True\n",
      "Gemm_1042.weight requires grad: True\n",
      "Gemm_1042.bias requires grad: True\n",
      "Gemm_1043.weight requires grad: True\n",
      "Gemm_1043.bias requires grad: True\n",
      "Gemm_1044.weight requires grad: True\n",
      "Gemm_1044.bias requires grad: True\n",
      "Gemm_1045.weight requires grad: True\n",
      "Gemm_1045.bias requires grad: True\n",
      "Gemm_1046.weight requires grad: True\n",
      "Gemm_1046.bias requires grad: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in pytorch_model.named_parameters():\n",
    "    print(name, 'requires grad:', param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (onnx)",
   "language": "python",
   "name": "onnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
